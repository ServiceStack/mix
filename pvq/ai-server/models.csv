id,url,short_desc
llama3.1,https://ollama.ai//library/llama3.1,"Llama 3.1 is a new state-of-the-art model from Meta available in 8B, 70B and 405B parameter sizes."
gemma2,https://ollama.ai//library/gemma2,"Google Gemma 2 is a high-performing and efficient model by now available in three sizes: 2B, 9B, and 27B."
mistral-nemo,https://ollama.ai//library/mistral-nemo,"A state-of-the-art 12B model with 128k context length, built by Mistral AI in collaboration with NVIDIA."
mistral-large,https://ollama.ai//library/mistral-large,"Mistral Large 2 is Mistral's new flagship model that is significantly more capable in code generation, mathematics, and reasoning with 128k context window and support for dozens of languages."
qwen2,https://ollama.ai//library/qwen2,"Qwen2 is a new series of large language models from Alibaba group"
deepseek-coder-v2,https://ollama.ai//library/deepseek-coder-v2,"An open-source Mixture-of-Experts code language model that achieves performance comparable to GPT4-Turbo in code-specific tasks."
phi3,https://ollama.ai//library/phi3,"Phi-3 is a family of lightweight 3B (Mini) and 14B (Medium) state-of-the-art open models by Microsoft."
mistral,https://ollama.ai//library/mistral,"The 7B model released by Mistral AI, updated to version 0.3."
mixtral,https://ollama.ai//library/mixtral,"A set of Mixture of Experts (MoE) model with open weights by Mistral AI in 8x7b and 8x22b parameter sizes."
codegemma,https://ollama.ai//library/codegemma,"CodeGemma is a collection of powerful, lightweight models that can perform a variety of coding tasks like fill-in-the-middle code completion, code generation, natural language understanding, mathematical reasoning, and instruction following."
command-r,https://ollama.ai//library/command-r,"Command R is a Large Language Model optimized for conversational interaction and long context tasks."
command-r-plus,https://ollama.ai//library/command-r-plus,"Command R+ is a powerful, scalable large language model purpose-built to excel at real-world enterprise use cases."
llava,https://ollama.ai//library/llava,"ðŸŒ‹ LLaVA is a novel end-to-end trained large multimodal model that combines a vision encoder and Vicuna for general-purpose visual and language understanding. Updated to version 1.6."
llama3,https://ollama.ai//library/llama3,"Meta Llama 3: The most capable openly available LLM to date"
gemma,https://ollama.ai//library/gemma,"Gemma is a family of lightweight, state-of-the-art open models built by Google DeepMind. Updated to version 1.1"
qwen,https://ollama.ai//library/qwen,"Qwen 1.5 is a series of large language models by Alibaba Cloud spanning from 0.5B to 110B parameters"
llama2,https://ollama.ai//library/llama2,"Llama 2 is a collection of foundation language models ranging from 7B to 70B parameters."
codellama,https://ollama.ai//library/codellama,"A large language model that can use text prompts to generate and discuss code."
dolphin-mixtral,https://ollama.ai//library/dolphin-mixtral,"Uncensored, 8x7b and 8x22b fine-tuned models based on the Mixtral mixture of experts models that excels at coding tasks. Created by Eric Hartford."
nomic-embed-text,https://ollama.ai//library/nomic-embed-text,"A high-performing open embedding model with a large token context window."
llama2-uncensored,https://ollama.ai//library/llama2-uncensored,"Uncensored Llama 2 model by George Sung and Jarrad Hope."
phi,https://ollama.ai//library/phi,"Phi-2: a 2.7B language model by Microsoft Research that demonstrates outstanding reasoning and language understanding capabilities."
deepseek-coder,https://ollama.ai//library/deepseek-coder,"DeepSeek Coder is a capable coding model trained on two trillion code and natural language tokens."
dolphin-mistral,https://ollama.ai//library/dolphin-mistral,"The uncensored Dolphin model based on Mistral that excels at coding tasks. Updated to version 2.8."
orca-mini,https://ollama.ai//library/orca-mini,"A general-purpose model ranging from 3 billion parameters to 70 billion, suitable for entry-level hardware."
mxbai-embed-large,https://ollama.ai//library/mxbai-embed-large,"State-of-the-art large embedding model from mixedbread.ai"
zephyr,https://ollama.ai//library/zephyr,"Zephyr is a series of fine-tuned versions of the Mistral and Mixtral models that are trained to act as helpful assistants."
dolphin-llama3,https://ollama.ai//library/dolphin-llama3,"Dolphin 2.9 is a new model with 8B and 70B sizes by Eric Hartford based on Llama 3 that has a variety of instruction, conversational, and coding skills."
starcoder2,https://ollama.ai//library/starcoder2,"StarCoder2 is the next generation of transparently trained open code LLMs that comes in three sizes: 3B, 7B and 15B parameters."
mistral-openorca,https://ollama.ai//library/mistral-openorca,"Mistral OpenOrca is a 7 billion parameter model, fine-tuned on top of the Mistral 7B model using the OpenOrca dataset."
yi,https://ollama.ai//library/yi,"Yi 1.5 is a high-performing, bilingual language model."
llama2-chinese,https://ollama.ai//library/llama2-chinese,"Llama 2 based model fine tuned to improve Chinese dialogue ability."
llava-llama3,https://ollama.ai//library/llava-llama3,"A LLaVA model fine-tuned from Llama 3 Instruct with better scores in several benchmarks."
vicuna,https://ollama.ai//library/vicuna,"General use chat model based on Llama and Llama 2 with 2K to 16K context sizes."
tinyllama,https://ollama.ai//library/tinyllama,"The TinyLlama project is an open endeavor to train a compact 1.1B Llama model on 3 trillion tokens."
nous-hermes2,https://ollama.ai//library/nous-hermes2,"The powerful family of models by Nous Research that excels at scientific discussion and coding tasks."
wizard-vicuna-uncensored,https://ollama.ai//library/wizard-vicuna-uncensored,"Wizard Vicuna Uncensored is a 7B, 13B, and 30B parameter model based on Llama 2 uncensored by Eric Hartford."
codestral,https://ollama.ai//library/codestral,"Codestral is Mistral AIâ€™s first-ever code model designed for code generation tasks."
starcoder,https://ollama.ai//library/starcoder,"StarCoder is a code generation model trained on 80+ programming languages."
wizardlm2,https://ollama.ai//library/wizardlm2,"State of the art large language model from Microsoft AI with improved performance on complex chat, multilingual, reasoning and agent use cases."
openchat,https://ollama.ai//library/openchat,"A family of open-source models trained on a wide variety of data, surpassing ChatGPT on various benchmarks. Updated to version 3.5-0106."
aya,https://ollama.ai//library/aya,"Aya 23, released by Cohere, is a new family of state-of-the-art, multilingual models that support 23 languages."
tinydolphin,https://ollama.ai//library/tinydolphin,"An experimental 1.1B parameter model trained on the new Dolphin 2.8 dataset by Eric Hartford and based on TinyLlama."
stable-code,https://ollama.ai//library/stable-code,"Stable Code 3B is a coding model with instruct and code completion variants on par with models such as Code Llama 7B that are 2.5x larger."
openhermes,https://ollama.ai//library/openhermes,"OpenHermes 2.5 is a 7B model fine-tuned by Teknium on Mistral with fully open datasets."
wizardcoder,https://ollama.ai//library/wizardcoder,"State-of-the-art code generation model"
codeqwen,https://ollama.ai//library/codeqwen,"CodeQwen1.5 is a large language model pretrained on a large amount of code data."
wizard-math,https://ollama.ai//library/wizard-math,"Model focused on math and logic problems"
granite-code,https://ollama.ai//library/granite-code,"A family of open foundation models by IBM for Code Intelligence"
stablelm2,https://ollama.ai//library/stablelm2,"Stable LM 2 is a state-of-the-art 1.6B and 12B parameter language model trained on multilingual data in English, Spanish, German, Italian, French, Portuguese, and Dutch."
neural-chat,https://ollama.ai//library/neural-chat,"A fine-tuned model based on Mistral with good coverage of domain and language."
all-minilm,https://ollama.ai//library/all-minilm,"Embedding models on very large sentence level datasets."
phind-codellama,https://ollama.ai//library/phind-codellama,"Code generation model based on Code Llama."
dolphincoder,https://ollama.ai//library/dolphincoder,"A 7B and 15B uncensored variant of the Dolphin model family that excels at coding, based on StarCoder2."
nous-hermes,https://ollama.ai//library/nous-hermes,"General use models based on Llama and Llama 2 from Nous Research."
sqlcoder,https://ollama.ai//library/sqlcoder,"SQLCoder is a code completion model fined-tuned on StarCoder for SQL generation tasks"
llama3-gradient,https://ollama.ai//library/llama3-gradient,"This model extends LLama-3 8B's context length from 8k to over 1m tokens."
xwinlm,https://ollama.ai//library/xwinlm,"Conversational model based on Llama 2 that performs competitively on various benchmarks."
starling-lm,https://ollama.ai//library/starling-lm,"Starling is a large language model trained by reinforcement learning from AI feedback focused on improving chatbot helpfulness."
yarn-llama2,https://ollama.ai//library/yarn-llama2,"An extension of Llama 2 that supports a context of up to 128k tokens."
deepseek-llm,https://ollama.ai//library/deepseek-llm,"An advanced language model crafted with 2 trillion bilingual tokens."
llama3-chatqa,https://ollama.ai//library/llama3-chatqa,"A model from NVIDIA based on Llama 3 that excels at conversational question answering (QA) and retrieval-augmented generation (RAG)."
falcon,https://ollama.ai//library/falcon,"A large language model built by the Technology Innovation Institute (TII) for use in summarization, text generation, and chat bots."
orca2,https://ollama.ai//library/orca2,"Orca 2 is built by Microsoft research, and are a fine-tuned version of Meta's Llama 2 models.  The model is designed to excel particularly in reasoning."
wizardlm,https://ollama.ai//library/wizardlm,"General use model based on Llama 2."
solar,https://ollama.ai//library/solar,"A compact, yet powerful 10.7B large language model designed for single-turn conversation."
samantha-mistral,https://ollama.ai//library/samantha-mistral,"A companion assistant trained in philosophy, psychology, and personal relationships. Based on Mistral."
dolphin-phi,https://ollama.ai//library/dolphin-phi,"2.7B uncensored Dolphin model by Eric Hartford, based on the Phi language model by Microsoft Research."
stable-beluga,https://ollama.ai//library/stable-beluga,"Llama 2 based model fine tuned on an Orca-style dataset. Originally called Free Willy."
moondream,https://ollama.ai//library/moondream,"moondream2 is a small vision language model designed to run efficiently on edge devices."
snowflake-arctic-embed,https://ollama.ai//library/snowflake-arctic-embed,"A suite of text embedding models by Snowflake, optimized for performance."
bakllava,https://ollama.ai//library/bakllava,"BakLLaVA is a multimodal model consisting of the Mistral 7B base model augmented with the LLaVA  architecture."
wizardlm-uncensored,https://ollama.ai//library/wizardlm-uncensored,"Uncensored version of Wizard LM model"
deepseek-v2,https://ollama.ai//library/deepseek-v2,"A strong, economical, and efficient Mixture-of-Experts language model."
medllama2,https://ollama.ai//library/medllama2,"Fine-tuned Llama 2 model to answer medical questions based on an open source medical dataset."
yarn-mistral,https://ollama.ai//library/yarn-mistral,"An extension of Mistral to support context windows of 64K or 128K."
llama-pro,https://ollama.ai//library/llama-pro,"An expansion of Llama 2 that specializes in integrating both general language understanding and domain-specific knowledge, particularly in programming and mathematics."
nous-hermes2-mixtral,https://ollama.ai//library/nous-hermes2-mixtral,"The Nous Hermes 2 model from Nous Research, now trained over Mixtral."
meditron,https://ollama.ai//library/meditron,"Open-source medical large language model adapted from Llama 2 to the medical domain."
nexusraven,https://ollama.ai//library/nexusraven,"Nexus Raven is a 13B instruction tuned model for function calling tasks."
codeup,https://ollama.ai//library/codeup,"Great code generation model based on Llama2."
llava-phi3,https://ollama.ai//library/llava-phi3,"A new small LLaVA model fine-tuned from Phi 3 Mini."
glm4,https://ollama.ai//library/glm4,"A strong multi-lingual general language model with competitive performance to Llama 3."
everythinglm,https://ollama.ai//library/everythinglm,"Uncensored Llama2 based model with support for a 16K context window."
codegeex4,https://ollama.ai//library/codegeex4,"A versatile model for AI software development scenarios, including code completion."
magicoder,https://ollama.ai//library/magicoder,"ðŸŽ© Magicoder is a family of 7B parameter models trained on 75K synthetic instruction data using OSS-Instruct, a novel approach to enlightening LLMs with open-source code snippets."
stablelm-zephyr,https://ollama.ai//library/stablelm-zephyr,"A lightweight chat model allowing accurate, and responsive output without requiring high-end hardware."
codebooga,https://ollama.ai//library/codebooga,"A high-performing code instruct model created by merging two existing code models."
mistrallite,https://ollama.ai//library/mistrallite,"MistralLite is a fine-tuned model based on Mistral with enhanced capabilities of processing long contexts."
wizard-vicuna,https://ollama.ai//library/wizard-vicuna,"Wizard Vicuna is a 13B parameter model based on Llama 2 trained by MelodysDreamj."
duckdb-nsql,https://ollama.ai//library/duckdb-nsql,"7B parameter text-to-SQL model made by MotherDuck and Numbers Station."
megadolphin,https://ollama.ai//library/megadolphin,"MegaDolphin-2.2-120b is a transformation of Dolphin-2.2-70b created by interleaving the model with itself."
goliath,https://ollama.ai//library/goliath,"A language model created by combining two fine-tuned Llama 2 70B models into one."
notux,https://ollama.ai//library/notux,"A top-performing mixture of experts model, fine-tuned with high-quality data."
falcon2,https://ollama.ai//library/falcon2,"Falcon2 is an 11B parameters causal decoder-only model built by TII and trained over 5T tokens."
open-orca-platypus2,https://ollama.ai//library/open-orca-platypus2,"Merge of the Open Orca OpenChat model and the Garage-bAInd Platypus 2 model. Designed for chat and code generation."
notus,https://ollama.ai//library/notus,"A 7B chat model fine-tuned with high-quality data and based on Zephyr."
dbrx,https://ollama.ai//library/dbrx,"DBRX is an open, general-purpose LLM created by Databricks."
internlm2,https://ollama.ai//library/internlm2,"InternLM2.5 is a 7B parameter model tailored for practical scenarios with outstanding reasoning capability."
alfred,https://ollama.ai//library/alfred,"A robust conversational model designed to be used for both chat and instruct use cases."
llama3-groq-tool-use,https://ollama.ai//library/llama3-groq-tool-use,"A series of models from Groq that represent a significant advancement in open-source AI capabilities for tool use/function calling."
mathstral,https://ollama.ai//library/mathstral,"MathÎ£tral: a 7B model designed for math reasoning and scientific discovery by Mistral AI."
firefunction-v2,https://ollama.ai//library/firefunction-v2,"An open weights function calling model based on Llama 3, competitive with GPT-4o function calling capabilities."
nuextract,https://ollama.ai//library/nuextract,"A 3.8B model fine-tuned on a private high-quality synthetic dataset for information extraction, based on Phi-3."
